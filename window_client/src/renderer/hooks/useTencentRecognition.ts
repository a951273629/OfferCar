import { useRef, useCallback } from 'react';
import type WebSocket from 'ws';
import {
  createTencentWebSocket,
  type TencentRecognitionResult,
} from '../lib/tencentSpeech';

export interface RecognitionTextMessage {
  role: 'interviewee' | 'interviewer';
  text: string;
  type: 'recognizing' | 'recognized';
  status: 'pending' | 'received';
  timestamp: number;
}

export interface UseTencentRecognitionResult {
  startRecognition: (onTextReceived: (message: RecognitionTextMessage) => void) => void;
  stopRecognition: () => void;
  sendAudioData: (role: 'interviewee' | 'interviewer', audioData: Int16Array) => void;
}

/**
 * è…¾è®¯äº‘åŒæµè¯­éŸ³è¯†åˆ« Hookï¼ˆElectron ç«¯ï¼‰
 */
export function useTencentRecognition(): UseTencentRecognitionResult {
  const intervieweeWsRef = useRef<WebSocket | null>(null);
  const interviewerWsRef = useRef<WebSocket | null>(null);

  const intervieweeSendTimerRef = useRef<NodeJS.Timeout | null>(null);
  const interviewerSendTimerRef = useRef<NodeJS.Timeout | null>(null);

  const intervieweeBufferRef = useRef<Int16Array[]>([]);
  const interviewerBufferRef = useRef<Int16Array[]>([]);

  const textCallbackRef = useRef<((message: RecognitionTextMessage) => void) | null>(null);

  /**
   * åˆ›å»º WebSocket å¹¶å¤„ç†è¯†åˆ«ç»“æœ
   */
  const createWebSocketConnection = (role: 'interviewee' | 'interviewer'): WebSocket => {
    console.log(`[Tencent Recognition] åˆ›å»º ${role === 'interviewee' ? 'é¢è¯•è€…' : 'é¢è¯•å®˜'} WebSocket...`);

    const ws = createTencentWebSocket();

    // è¿æ¥æ‰“å¼€
    ws.on('open', () => {
      console.log(`[Tencent Recognition] ${role === 'interviewee' ? 'ğŸ¤ é¢è¯•è€…' : 'ğŸ‘” é¢è¯•å®˜'} WebSocket å·²è¿æ¥`);
    });

    // æ¥æ”¶æ¶ˆæ¯
    ws.on('message', (data: Buffer) => {
      try {
        const result: TencentRecognitionResult = JSON.parse(data.toString());

        // æ£€æŸ¥é”™è¯¯
        if (result.code !== 0) {
          console.error(`[Tencent Recognition] ${role} è¯†åˆ«é”™è¯¯ [${result.code}]:`, result.message);
          return;
        }

        // å¤„ç†è¯†åˆ«ç»“æœ
        if (result.result && result.result.voice_text_str) {
          const text = result.result.voice_text_str.trim();

          if (text && textCallbackRef.current) {
            // slice_type: 0=å¼€å§‹, 1=ä¸­é—´, 2=ç»“æŸ
            const type = result.result.slice_type === 2 ? 'recognized' : 'recognizing';
            const status = result.result.slice_type === 2 ? 'received' : 'pending';

            console.log(
              `[Tencent Recognition] ${role === 'interviewee' ? 'ğŸ¤' : 'ğŸ‘”'} [${type}] [${status}]:`,
              text
            );

            textCallbackRef.current({
              role,
              text,
              type,
              status,
              timestamp: Date.now()
            });
          }
        }

        // è¯†åˆ«å®Œæˆ
        if (result.final === 1) {
          console.log(`[Tencent Recognition] ${role} è¯†åˆ«å®Œæˆ`);
        }
      } catch (err) {
        console.error(`[Tencent Recognition] ${role} è§£ææ¶ˆæ¯å¤±è´¥:`, err);
      }
    });

    // è¿æ¥å…³é—­
    ws.on('close', (code, reason) => {
      console.log(
        `[Tencent Recognition] ${role === 'interviewee' ? 'ğŸ¤ é¢è¯•è€…' : 'ğŸ‘” é¢è¯•å®˜'} WebSocket å·²å…³é—­`,
        `code: ${code}, reason: ${reason.toString()}`
      );
    });

    // è¿æ¥é”™è¯¯
    ws.on('error', (error) => {
      console.error(`[Tencent Recognition] ${role} WebSocket é”™è¯¯:`, error.message);
    });

    return ws;
  };

  /**
   * å¯åŠ¨å‘é€å®šæ—¶å™¨
   */
  const startSendTimer = (
    role: 'interviewee' | 'interviewer',
    ws: WebSocket,
    bufferRef: React.MutableRefObject<Int16Array[]>,
    timerRef: React.MutableRefObject<NodeJS.Timeout | null>
  ) => {
    // é™éŸ³æ•°æ®åŒ…ï¼ˆ16kHz, 40ms = 640 æ ·æœ¬ï¼‰
    const silencePacket = new Int16Array(640).fill(0);

    // æ¯ 40ms å‘é€ä¸€æ¬¡
    timerRef.current = setInterval(() => {
      if (bufferRef.current.length > 0) {
        // åˆå¹¶ç¼“å†²çš„æ•°æ®
        const totalLength = bufferRef.current.reduce((sum, arr) => sum + arr.length, 0);
        const mergedData = new Int16Array(totalLength);
        let offset = 0;

        for (const chunk of bufferRef.current) {
          mergedData.set(chunk, offset);
          offset += chunk.length;
        }

        // å‘é€çœŸå®éŸ³é¢‘æ•°æ®
        if (ws.readyState === 1) {
          const audioBytes = Buffer.from(mergedData.buffer);
          ws.send(audioBytes);
        }

        // æ¸…ç©ºç¼“å†²åŒº
        bufferRef.current = [];
      } else {
        // å‘é€é™éŸ³æ•°æ®åŒ…ä¿æŒè¿æ¥
        if (ws.readyState === 1) {
          const audioBytes = Buffer.from(silencePacket.buffer);
          ws.send(audioBytes);
        }
      }
    }, 40); // 40ms
  };

  /**
   * å¯åŠ¨åŒæµè¯†åˆ«
   */
  const startRecognition = useCallback((onTextReceived: (message: RecognitionTextMessage) => void) => {
    console.log('â•'.repeat(50));
    console.log('[Tencent Recognition] ğŸ™ï¸ å¯åŠ¨åŒæµè¯†åˆ«æ¨¡å¼ï¼ˆElectron ç«¯ï¼‰');

    textCallbackRef.current = onTextReceived;

    // åˆ›å»ºé¢è¯•è€… WebSocket
    const intervieweeWs = createWebSocketConnection('interviewee');
    intervieweeWsRef.current = intervieweeWs;

    // åˆ›å»ºé¢è¯•å®˜ WebSocket
    const interviewerWs = createWebSocketConnection('interviewer');
    interviewerWsRef.current = interviewerWs;

    // ç­‰å¾…è¿æ¥æ‰“å¼€åå¯åŠ¨å®šæ—¶å™¨
    intervieweeWs.on('open', () => {
      console.log('[Tencent Recognition] ğŸ¤ é¢è¯•è€…å®šæ—¶å™¨å·²å¯åŠ¨');
      startSendTimer('interviewee', intervieweeWs, intervieweeBufferRef, intervieweeSendTimerRef);
    });

    interviewerWs.on('open', () => {
      console.log('[Tencent Recognition] ğŸ‘” é¢è¯•å®˜å®šæ—¶å™¨å·²å¯åŠ¨');
      startSendTimer('interviewer', interviewerWs, interviewerBufferRef, interviewerSendTimerRef);
      
      console.log('â•'.repeat(50));
      console.log('[Tencent Recognition] âœ… åŒæµè¯†åˆ«å·²å…¨éƒ¨å¯åŠ¨');
      console.log('â•'.repeat(50));
    });
  }, []);

  /**
   * åœæ­¢è¯†åˆ«
   */
  const stopRecognition = useCallback(() => {
    console.log('[Tencent Recognition] åœæ­¢è¯†åˆ«');

    // åœæ­¢å®šæ—¶å™¨
    if (intervieweeSendTimerRef.current) {
      clearInterval(intervieweeSendTimerRef.current);
      intervieweeSendTimerRef.current = null;
    }

    if (interviewerSendTimerRef.current) {
      clearInterval(interviewerSendTimerRef.current);
      interviewerSendTimerRef.current = null;
    }

    // å‘é€ç»“æŸæ¶ˆæ¯å¹¶å…³é—­
    if (intervieweeWsRef.current && intervieweeWsRef.current.readyState === 1) {
      intervieweeWsRef.current.send(JSON.stringify({ type: 'end' }));
      intervieweeWsRef.current.close();
      intervieweeWsRef.current = null;
    }

    if (interviewerWsRef.current && interviewerWsRef.current.readyState === 1) {
      interviewerWsRef.current.send(JSON.stringify({ type: 'end' }));
      interviewerWsRef.current.close();
      interviewerWsRef.current = null;
    }

    // æ¸…ç©ºç¼“å†²åŒº
    intervieweeBufferRef.current = [];
    interviewerBufferRef.current = [];

    textCallbackRef.current = null;
  }, []);

  /**
   * å‘é€éŸ³é¢‘æ•°æ®
   */
  const sendAudioData = useCallback((role: 'interviewee' | 'interviewer', audioData: Int16Array) => {
    if (role === 'interviewee') {
      intervieweeBufferRef.current.push(audioData);
    } else {
      interviewerBufferRef.current.push(audioData);
    }
  }, []);

  return {
    startRecognition,
    stopRecognition,
    sendAudioData
  };
}

