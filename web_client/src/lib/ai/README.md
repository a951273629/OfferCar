# AI å®¢æˆ·ç«¯æ¶æ„æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ AI å®¢æˆ·ç«¯æ¶æ„ï¼Œæ”¯æŒå¤šä¸ª AI Providerï¼ˆOpenAIã€Geminiï¼‰ï¼Œæä¾›æµå¼è¾“å‡ºå’Œæ€è€ƒæ¨¡å¼æ”¯æŒã€‚

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

- **60fps æµå¼è¾“å‡º**ï¼šä½¿ç”¨ `requestAnimationFrame` å®ç°ä¸æ»‘çš„æ–‡æœ¬æ¸²æŸ“
- **æ€è€ƒæ¨¡å¼æ”¯æŒ**ï¼š
  - OpenAIï¼šè‡ªåŠ¨è¯†åˆ« `reasoning_content` å­—æ®µï¼ˆo1 ç³»åˆ—æ¨¡å‹ï¼‰
  - Geminiï¼šè‡ªåŠ¨è¯†åˆ« `<think>` æ ‡ç­¾
- **Provider æŠ½è±¡å±‚**ï¼šæ˜“äºæ‰©å±•æ–°çš„ AI æœåŠ¡å•†
- **ç»Ÿä¸€ API æ¥å£**ï¼šæ‰€æœ‰ Provider ä½¿ç”¨ç›¸åŒçš„è°ƒç”¨æ–¹å¼
- **TypeScript æ”¯æŒ**ï¼šå®Œæ•´çš„ç±»å‹å®šä¹‰

## ğŸ“¦ é¡¹ç›®ç»“æ„

```
src/lib/ai/
â”œâ”€â”€ base.ts                # LLMApi æŠ½è±¡åŸºç±»
â”œâ”€â”€ client.ts              # Provider å·¥å‚å‡½æ•°å’Œå¯¼å‡º
â”œâ”€â”€ config.ts              # ç¯å¢ƒå˜é‡é…ç½®ç®¡ç†
â”œâ”€â”€ stream.ts              # æ ¸å¿ƒæµå¼å¤„ç†é€»è¾‘ï¼ˆ60fps åŠ¨ç”»ï¼‰
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ openai.ts          # OpenAI SSE è§£æå™¨
â”‚   â””â”€â”€ gemini.ts          # Gemini SSE è§£æå™¨
â””â”€â”€ providers/
    â”œâ”€â”€ openai.ts          # OpenAI å®¢æˆ·ç«¯å®ç°
    â””â”€â”€ gemini.ts          # Gemini å®¢æˆ·ç«¯å®ç°

src/hooks/
â””â”€â”€ useAIChat.ts           # React Hook å°è£…

src/types/
â””â”€â”€ api.ts                 # ç±»å‹å®šä¹‰
```

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env.local` æ–‡ä»¶å¹¶æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```bash
# é»˜è®¤ Providerï¼ˆå¯é€‰: openai | geminiï¼‰
AI_PROVIDER=gemini

# OpenAI é…ç½®
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_API_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# Gemini é…ç½®
GEMINI_API_KEY=your-gemini-api-key
GEMINI_API_URL=https://generativelanguage.googleapis.com/v1
GEMINI_MODEL=gemini-2.0-flash-exp

# å‘åå…¼å®¹ï¼ˆä¼˜å…ˆçº§ä½ï¼‰
AI_API_KEY=your-api-key
AI_API_URL=https://generativelanguage.googleapis.com/v1
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€ç”¨æ³•ï¼ˆç›´æ¥è°ƒç”¨ï¼‰

```typescript
import { sendChatRequest } from '@/lib/ai/client';
import { AIProvider } from '@/types/api';
import { nanoid } from 'nanoid';

await sendChatRequest({
  messages: [
    {
      id: nanoid(),
      role: 'user',
      content: 'Hello, AI!',
      date: new Date().toISOString(),
    }
  ],
  config: {
    provider: AIProvider.Gemini,
    stream: true,
  },
  onUpdate: (message, chunk) => {
    console.log('Chunk:', chunk);
  },
  onFinish: (message) => {
    console.log('Done:', message);
  },
  onError: (err) => {
    console.error('Error:', err);
  },
});
```

### 2. ä½¿ç”¨ React Hook

```typescript
import { useAIChat } from '@/hooks/useAIChat';
import { AIProvider } from '@/types/api';

function ChatComponent() {
  const { sendMessage, isStreaming, streamingContent } = useAIChat();

  const handleSend = async () => {
    const response = await sendMessage(
      'Hello, AI!',
      'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŠ©æ‰‹',
      AIProvider.OpenAI
    );
    
    if (response) {
      console.log('AI å›å¤:', response.content);
    }
  };

  return (
    <div>
      <button onClick={handleSend} disabled={isStreaming}>
        å‘é€æ¶ˆæ¯
      </button>
      {isStreaming && <div>{streamingContent}</div>}
    </div>
  );
}
```

### 3. åœ¨ API è·¯ç”±ä¸­ä½¿ç”¨

```typescript
// app/api/custom-chat/route.ts
import { getAIClient } from '@/lib/ai/client';
import { AIProvider, ChatMessage } from '@/types/api';
import { nanoid } from 'nanoid';

export async function POST(request: Request) {
  const { message } = await request.json();
  
  const client = getAIClient(AIProvider.OpenAI);
  
  const encoder = new TextEncoder();
  const stream = new ReadableStream({
    async start(controller) {
      await client.chat({
        messages: [{
          id: nanoid(),
          role: 'user',
          content: message,
          date: new Date().toISOString(),
        }],
        config: { stream: true },
        onUpdate: (msg, chunk) => {
          const data = `data: ${JSON.stringify({ chunk })}\n\n`;
          controller.enqueue(encoder.encode(data));
        },
        onFinish: (msg) => {
          controller.close();
        },
        onError: (err) => {
          console.error(err);
          controller.close();
        },
      });
    },
  });

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}
```

## ğŸ”Œ æ‰©å±•æ–° Provider

å¦‚éœ€æ·»åŠ æ–°çš„ AI Providerï¼ˆå¦‚ Claudeã€PaLM ç­‰ï¼‰ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

### æ­¥éª¤ 1ï¼šæ·»åŠ  Provider æšä¸¾

```typescript
// src/types/api.ts
export enum AIProvider {
  OpenAI = 'openai',
  Gemini = 'gemini',
}
```

### æ­¥éª¤ 2ï¼šæ·»åŠ é…ç½®

```typescript
// src/lib/ai/config.ts
export interface AIConfig {
  provider: AIProvider;
  openai: { ... };
  gemini: { ... };
  claude: {  // æ–°å¢
    apiKey: string;
    baseUrl: string;
    model: string;
  };
}

export function getAIConfig(): AIConfig {
  return {
    // ... existing code ...
    claude: {
      apiKey: process.env.CLAUDE_API_KEY || '',
      baseUrl: process.env.CLAUDE_API_URL || 'https://api.anthropic.com',
      model: process.env.CLAUDE_MODEL || 'claude-3-sonnet',
    },
  };
}
```

### æ­¥éª¤ 3ï¼šåˆ›å»º SSE è§£æå™¨

```typescript
// src/lib/ai/parsers/claude.ts
import { SSEParseResult } from '../stream';

export function parseClaudeSSE(text: string): SSEParseResult {
  // å®ç° Claude çš„ SSE è§£æé€»è¾‘
  const json = JSON.parse(text);
  return {
    isThinking: false,
    content: json.delta?.text || '',
  };
}
```

### æ­¥éª¤ 4ï¼šåˆ›å»º Provider å®ç°

```typescript
// src/lib/ai/providers/claude.ts
import { LLMApi } from '../base';  // ä» base.ts å¯¼å…¥
import { ChatOptions } from '@/types/api';
import { getAIConfig } from '../config';
import { streamWithThink } from '../stream';
import { parseClaudeSSE } from '../parsers/claude';

export class ClaudeClient extends LLMApi {
  async chat(options: ChatOptions): Promise<void> {
    const config = getAIConfig();
    const { apiKey, baseUrl, model } = config.claude;

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼
    const messages = options.messages.map(msg => ({
      role: msg.role,
      content: msg.content,
    }));

    // æ„å»ºè¯·æ±‚
    const requestPayload = {
      model,
      messages,
      stream: true,
    };

    const controller = new AbortController();
    options.onController?.(controller);

    await streamWithThink(
      `${baseUrl}/v1/messages`,
      requestPayload,
      {
        'Content-Type': 'application/json',
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01',
      },
      controller,
      parseClaudeSSE,
      options
    );
  }
}
```

### æ­¥éª¤ 5ï¼šæ³¨å†Œåˆ°å·¥å‚å‡½æ•°

```typescript
// src/lib/ai/client.ts
export function getAIClient(provider?: AIProvider): LLMApi {
  // ... existing code ...
  switch (actualProvider) {
    case AIProvider.OpenAI:
      return new OpenAIClient();
    case AIProvider.Gemini:
      return new GeminiClient();
    case AIProvider.Claude:  // æ–°å¢
      const { ClaudeClient } = require('./providers/claude');
      return new ClaudeClient();
    default:
      throw new Error(`ä¸æ”¯æŒçš„ AI Provider: ${actualProvider}`);
  }
}
```

## ğŸ¯ æ ¸å¿ƒåŸç†

### 60fps æµå¼åŠ¨ç”»

ä½äº `src/lib/ai/stream.ts` çš„ `animateResponseText()` å‡½æ•°ï¼š

```typescript
function animateResponseText() {
  if (remainText.length > 0) {
    // æ¯å¸§æ¸²æŸ“å‰©ä½™æ–‡æœ¬çš„ 1/60ï¼Œå®ç° 60fps å¹³æ»‘åŠ¨ç”»
    const fetchCount = Math.max(1, Math.round(remainText.length / 60));
    const fetchText = remainText.slice(0, fetchCount);
    responseText += fetchText;
    remainText = remainText.slice(fetchCount);
    options.onUpdate?.(responseText, fetchText);
  }
  requestAnimationFrame(animateResponseText);
}
```

### æ€è€ƒæ¨¡å¼è¯†åˆ«

- **OpenAI**ï¼šé€šè¿‡ `reasoning_content` å­—æ®µè¯†åˆ«ï¼ˆo1 æ¨¡å‹ï¼‰
- **Gemini**ï¼šé€šè¿‡ `<think>` æ ‡ç­¾è¯†åˆ«

æ€è€ƒå†…å®¹ä»¥å¼•ç”¨æ ¼å¼æ˜¾ç¤ºï¼ˆ`> æ€è€ƒå†…å®¹`ï¼‰ã€‚

### SSE è¿æ¥ç®¡ç†

ä½¿ç”¨ `@fortaine/fetch-event-source` åº“ï¼š
- è‡ªåŠ¨é‡è¿
- é”™è¯¯å¤„ç†
- è¶…æ—¶æ§åˆ¶ï¼ˆ60 ç§’ï¼‰

## ğŸ› æ•…éšœæ’æŸ¥

### 1. è¿æ¥å¤±è´¥

**é—®é¢˜**ï¼š`AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨`

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦é…ç½®æ­£ç¡®
- éªŒè¯ API Key æ˜¯å¦æœ‰æ•ˆ
- æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®

### 2. æµå¼è¾“å‡ºå¡é¡¿

**é—®é¢˜**ï¼šæ–‡æœ¬æ˜¾ç¤ºä¸æµç•…

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®è®¤åç«¯æ­£ç¡®å®ç°äº† `streamWithThink` å‡½æ•°
- æ£€æŸ¥å‰ç«¯æ˜¯å¦æ­£ç¡®è§£æ SSE æ•°æ®
- ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·æŸ¥çœ‹ç½‘ç»œè¯·æ±‚

### 3. æ€è€ƒæ¨¡å¼ä¸æ˜¾ç¤º

**é—®é¢˜**ï¼šOpenAI o1 æ¨¡å‹çš„æ€è€ƒå†…å®¹æœªæ˜¾ç¤º

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®è®¤ä½¿ç”¨çš„æ˜¯ o1 ç³»åˆ—æ¨¡å‹ï¼ˆå¦‚ `o1-preview`ï¼‰
- æ£€æŸ¥ `parseOpenAISSE` æ˜¯å¦æ­£ç¡®è§£æ `reasoning_content`
- éªŒè¯ `streamWithThink` çš„æ€è€ƒæ¨¡å¼é€»è¾‘

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

1. **å‡å°‘é‡å¤æ¸²æŸ“**ï¼š
   - ä½¿ç”¨ `React.memo` åŒ…è£…æ¶ˆæ¯ç»„ä»¶
   - é¿å…åœ¨æ¸²æŸ“å‡½æ•°ä¸­åˆ›å»ºæ–°å¯¹è±¡

2. **æ‡’åŠ è½½ Provider**ï¼š
   - ä½¿ç”¨åŠ¨æ€ `require()` å¯¼å…¥ Provider
   - é¿å…æ‰“åŒ…æœªä½¿ç”¨çš„ Provider ä»£ç 

3. **æµå¼ç¼“å†²**ï¼š
   - `remainText` ç¼“å†²åŒºå¹³æ»‘è¾“å‡º
   - é¿å…é¢‘ç¹çš„ DOM æ›´æ–°

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-01-xx)
- âœ… åˆå§‹ç‰ˆæœ¬
- âœ… æ”¯æŒ OpenAI å’Œ Gemini
- âœ… 60fps æµå¼åŠ¨ç”»
- âœ… æ€è€ƒæ¨¡å¼æ”¯æŒ
- âœ… Provider æŠ½è±¡å±‚
- âœ… React Hook å°è£…

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

